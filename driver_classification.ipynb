{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading finished. Elapsed time:  5.861717462539673\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Read data\n",
    "t1 = time.time()\n",
    "points = pd.read_csv('inc_points_2.csv')\n",
    "tracks = pd.read_csv('rich_tracks_2.csv')\n",
    "os = pd.read_csv('os.csv')\n",
    "t2 = time.time()\n",
    "print('Loading finished. Elapsed time: ', t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaing finished. Elapsed time:  0.5926382541656494\n"
     ]
    }
   ],
   "source": [
    "# Clean data, fix different (iOS/Android) dimensions of latitude and longitude \n",
    "t1 = time.time()\n",
    "points.drop(['PointDate'], axis=1, inplace=True)\n",
    "points = points.round({'Latitude': 6, 'Longitude': 6})\n",
    "needed_cols = ['IncomingTrackId', 'TrackOrigin']\n",
    "merged = pd.merge(points, tracks[needed_cols])\n",
    "t2 = time.time()\n",
    "print('Cleaing finished. Elapsed time: ', t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, test generating finished. Elapsed time:  50.80956697463989\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering, generating train, test dataframes\n",
    "t1 = time.time()\n",
    "\n",
    "# Feature vector of each track would contain N points (latitude, logitude), \n",
    "# where N=num_points. This hyperparameter greatly affects accuracy.\n",
    "num_points = 12\n",
    "\n",
    "features = ['MeanSpeed',\n",
    "            'MaxSpeed',\n",
    "            'MeanAcceleration',\n",
    "            'MaxAcceleration',\n",
    "            'MeanDeceleration',\n",
    "            'MaxDeceleration',\n",
    "            'MeanAccelerationX',\n",
    "            'MaxAccelerationX',\n",
    "            'MeanAccelerationY',\n",
    "            'MaxAccelerationY',\n",
    "            'MeanAccelerationZ',\n",
    "            'MaxAccelerationZ',\n",
    "            'MeanHeight',\n",
    "            'StartTimestamp',\n",
    "            'EndTimestamp',\n",
    "            'TrackOrigin']\n",
    "\n",
    "num_feat_cols = len(features)\n",
    "\n",
    "for i in range(num_points):\n",
    "    features.append('Point' + str(i) + 'Latitude')\n",
    "    features.append('Point' + str(i) + 'Longitude')\n",
    "\n",
    "feat_df = pd.DataFrame(columns=features)\n",
    "\n",
    "# Create feature vector for every unique track \n",
    "for i, id in enumerate(merged.IncomingTrackId.unique()):\n",
    "    track = merged.loc[merged['IncomingTrackId']==id]\n",
    "\n",
    "    if num_points == 1:\n",
    "        feat_df = train.append(track.iloc[0])\n",
    "    else:\n",
    "        step = math.ceil(len(track)/(num_points))\n",
    "        j = 0\n",
    "\n",
    "        if len(track) < num_points:\n",
    "            print('len(track) < num_points')\n",
    "\n",
    "        # Adding features\n",
    "        feat_df = feat_df.append({'MeanSpeed':track['Speed'].mean()}, ignore_index=True)\n",
    "        feat_df['MaxSpeed'].iloc[i] = track['Speed'].max()\n",
    "        feat_df['MeanAcceleration'].iloc[i] = track['Acceleration'].mean()\n",
    "        feat_df['MaxAcceleration'].iloc[i] = track['Acceleration'].max()\n",
    "        feat_df['MeanDeceleration'].iloc[i] = track['Deceleration'].mean()\n",
    "        feat_df['MaxDeceleration'].iloc[i] = track['Deceleration'].max()\n",
    "        feat_df['MeanAccelerationX'].iloc[i] = track['AccelerationXOriginal'].mean()\n",
    "        feat_df['MaxAccelerationX'].iloc[i] = track['AccelerationXOriginal'].max()\n",
    "        feat_df['MeanAccelerationY'].iloc[i] = track['AccelerationYOriginal'].mean()\n",
    "        feat_df['MaxAccelerationY'].iloc[i] = track['AccelerationYOriginal'].max()\n",
    "        feat_df['MeanAccelerationZ'].iloc[i] = track['AccelerationZOriginal'].mean()\n",
    "        feat_df['MaxAccelerationZ'].iloc[i] = track['AccelerationZOriginal'].max()\n",
    "        feat_df['MeanHeight'].iloc[i] = track['Height'].mean()\n",
    "        feat_df['StartTimestamp'].iloc[i] = track['TickTimestamp'].min()\n",
    "        feat_df['EndTimestamp'].iloc[i] = track['TickTimestamp'].max()\n",
    "        feat_df['TrackOrigin'].iloc[i] = track['TrackOrigin'].iloc[0]\n",
    "\n",
    "        # Adding points\n",
    "        k = 0\n",
    "        while j < len(track):\n",
    "            feat_df.iloc[i, k + num_feat_cols] = track.iloc[j, 2]\n",
    "            feat_df.iloc[i, k + num_feat_cols + 1] = track.iloc[j, 3]\n",
    "            j += step\n",
    "            k += 2\n",
    "\n",
    "feat_df = feat_df.dropna()\n",
    "driver_mapping = {'OriginalDriver': 1, 'Passanger': 0, 'Taxi': 0}\n",
    "feat_df['TrackOrigin'] = feat_df['TrackOrigin'].map(driver_mapping)\n",
    "feat_df = feat_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "train_part = math.floor(len(feat_df) * 0.7)  # number of rows for train dataframe\n",
    "train = feat_df.iloc[:train_part, :]\n",
    "test = feat_df.iloc[train_part:, :]\n",
    "train_target = train['TrackOrigin']\n",
    "test_target = test['TrackOrigin']\n",
    "train.drop(['TrackOrigin'], axis=1, inplace=True)\n",
    "test.drop(['TrackOrigin'], axis=1, inplace=True)\n",
    "t2 = time.time()    \n",
    "print('train, test generating finished. Elapsed time: ', t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy:  76.57\n",
      "KNN accuracy:  98.95\n",
      "Decision Tree accuracy:  99.28\n",
      "Random Forest accuracy:  99.22\n",
      "Naive Bayes accuracy:  86.78\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validation of SVM, kNN, Decision Tree, Random Forest and Naive Bayes models\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "model = SVC()\n",
    "accuracy = cross_val_score(model, train, train_target, cv=k_fold, n_jobs=1, scoring='accuracy')\n",
    "print('SVM accuracy: ', round(np.mean(accuracy)*100, 2))\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors = 9)\n",
    "accuracy = cross_val_score(model, train, train_target, cv=k_fold, n_jobs=1, scoring='accuracy')\n",
    "print('KNN accuracy: ', round(np.mean(accuracy)*100, 2))\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "accuracy = cross_val_score(model, train, train_target, cv=k_fold, n_jobs=1, scoring='accuracy')\n",
    "print('Decision Tree accuracy: ', round(np.mean(accuracy)*100, 2))\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=14)\n",
    "accuracy = cross_val_score(model, train, train_target, cv=k_fold, n_jobs=1, scoring='accuracy')\n",
    "print('Random Forest accuracy: ', round(np.mean(accuracy)*100, 2))\n",
    "\n",
    "model = GaussianNB()\n",
    "accuracy = cross_val_score(model, train, train_target, cv=k_fold, n_jobs=1, scoring='accuracy')\n",
    "print('Naive Bayes accuracy: ', round(np.mean(accuracy)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TrackOrigin  Prediction\n",
      "1801            1           1\n",
      "1802            0           0\n",
      "1803            1           1\n",
      "1804            1           1\n",
      "1805            1           1\n",
      "1806            1           1\n",
      "1807            0           0\n",
      "1808            1           1\n",
      "1809            1           1\n",
      "1810            0           0\n",
      "1811            1           1\n",
      "1812            0           0\n",
      "1813            1           1\n",
      "1814            1           1\n",
      "1815            1           1\n",
      "1816            0           0\n",
      "1817            0           0\n",
      "1818            1           1\n",
      "1819            1           1\n",
      "1820            1           1\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "model = RandomForestClassifier(n_estimators=14)\n",
    "model.fit(train, train_target)\n",
    "prediction = model.predict(test)\n",
    "check = pd.DataFrame({\"TrackOrigin\": test_target, \"Prediction\": prediction})\n",
    "print(check.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
